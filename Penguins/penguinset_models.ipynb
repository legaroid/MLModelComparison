{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Model Comparison\n",
        "\n",
        "In this notebook, we compare the performance of several classification models using the penguins dataset. We will use cross-validation to evaluate the models and determine the best performing one."
      ],
      "metadata": {
        "id": "p_S6lBp0LP3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Description\n",
        "\n",
        "The dataset contains information about penguins, including their species and various measurements."
      ],
      "metadata": {
        "id": "jY3NKXTr0yM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries\n",
        "\n",
        "We begin by importing the necessary libraries for data manipulation, visualization, and model building."
      ],
      "metadata": {
        "id": "6efVn6yj02HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "N66KXxhs09VL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preprocessing the Data\n",
        "Next, we load the dataset and preprocess it by handling missing values and encoding categorical variables."
      ],
      "metadata": {
        "id": "u3PjxKqg0_Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('penguins.csv')\n",
        "df = df.dropna(subset=[\"sex\"]).copy()\n",
        "X = df.drop(\"sex\", axis=1)\n",
        "y = df[\"sex\"]\n",
        "\n",
        "# Preprocessing\n",
        "categoric_columns = []\n",
        "numeric_columns = []\n",
        "for col in X.columns:\n",
        "    if X[col].dtype == 'O':\n",
        "        categoric_columns.append(col)\n",
        "    else:\n",
        "        numeric_columns.append(col)\n",
        "\n",
        "categoric_transformer = Pipeline(steps=[\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"z_scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('cat', categoric_transformer, categoric_columns),\n",
        "    ('num', numeric_transformer, numeric_columns)\n",
        "])"
      ],
      "metadata": {
        "id": "zHCfxoTstCgP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation\n",
        "We train multiple classifiers using cross-validation and evaluate their performance."
      ],
      "metadata": {
        "id": "d5BipzXtTH-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"SVC\": SVC(),\n",
        "    \"GNB\": GaussianNB(),\n",
        "    \"LDA\": LinearDiscriminantAnalysis(),\n",
        "    \"LR\": LogisticRegression(n_jobs=-1)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, classifier in classifiers.items():\n",
        "    pipe = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        (\"classifier\", classifier)\n",
        "    ])\n",
        "    scores = cross_val_score(pipe, X, y, cv=4, scoring='accuracy')\n",
        "    results[name] = scores.mean()\n",
        "\n",
        "best_model = max(results, key=results.get)\n",
        "print(\"Accuracy scores:\")\n",
        "for name, score in results.items():\n",
        "    print(f\"{name}: {score}\")\n",
        "print(f\"\\nBest model: {best_model} with accuracy {results[best_model]}\")\n",
        "print(\"\")\n",
        "print(f\"*LR = logistic Regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwE1yOS1TQpC",
        "outputId": "9ae04ab1-0045-4e1d-bba7-3cac0ea291fe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy scores:\n",
            "KNN: 0.858720596672404\n",
            "SVC: 0.9159853700516352\n",
            "GNB: 0.6428930005737234\n",
            "LDA: 0.8229704532415376\n",
            "LR: 0.8770080321285141\n",
            "\n",
            "Best model: SVC with accuracy 0.9159853700516352\n",
            "\n",
            "*LR = logistic Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-mluNOzTUfV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}